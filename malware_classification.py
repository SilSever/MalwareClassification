"""
Silvio Severino - malware classification
"""
import main
from sklearn.svm import SVC
from sklearn import linear_model
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
import numpy as np
import matplotlib.pyplot as plt
from prettytable import PrettyTable


print ("Reading data ...")
x_all, y_all = main.read(LOAD_DATA=False)
x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.3, random_state=42)

modelLogistic = [
        linear_model.LogisticRegression(),
        linear_model.LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                                        intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
                                        penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
                                        verbose=0, warm_start=False),
        linear_model.LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                                        intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
                                        penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
                                        verbose=0, warm_start=False)]
for model in modelLogistic:
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuLog = accuracy_score(y_test, y_pred)
    fLog = f1_score(y_test, y_pred)

modelSvm = [SVC(),
              SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,
                  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
                  max_iter=-1, probability=False, random_state=None, shrinking=True,
                  tol=0.001, verbose=False)
              ]
for model in modelSvm:
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuSvm = accuracy_score(y_test, y_pred)
    fSvm = f1_score(y_test, y_pred)


modelRf = [RandomForestClassifier(),
          RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                                 max_depth=None, max_features='sqrt', max_leaf_nodes=None,
                                 min_impurity_decrease=0.0, min_impurity_split=None,
                                 min_samples_leaf=1, min_samples_split=2,
                                 min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
                                 oob_score=False, random_state=None, verbose=0,
                                 warm_start=False),
          RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                                 max_depth=None, max_features='sqrt', max_leaf_nodes=None,
                                 min_impurity_decrease=0.0, min_impurity_split=None,
                                 min_samples_leaf=1, min_samples_split=2,
                                 min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
                                 oob_score=False, random_state=None, verbose=0,
                                 warm_start=False)
          ]
for model in modelRf:
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuRf = accuracy_score(y_test, y_pred)
    fRf = f1_score(y_test, y_pred)

forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                                max_depth=None, max_features='sqrt', max_leaf_nodes=None,
                                min_impurity_decrease=0.0, min_impurity_split=None,
                                min_samples_leaf=1, min_samples_split=2,
                                min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,
                                oob_score=False, random_state=None, verbose=0,
                                warm_start=False)

#Show the result
table = PrettyTable()
print("Malware classification")
table.field_names = ["Algorithms", "Accuracy", "F1 score"]
table.add_row(["Logistic regression", accuLog, fLog])
table.add_row(["Support vector machine", accuSvm, fSvm])
table.add_row(["Random forest", accuRf, fRf])
print(table)

# Show the plot of features
forest = modelRf[0]
forest.fit(x_all, y_all)
importances = forest.feature_importances_
std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)
indices = np.argsort(importances)[::-1]
plt.figure()
plt.title("Feature importances")
indices = sorted(indices)
indices_text = ['S0','S1','S2','S3','S4','S5','S6','S7','S8',]
plt.bar(range(x_all.shape[1]), importances[indices], color="g", yerr=std[indices], align="center")
plt.xticks(range(x_all.shape[1]), indices_text)
plt.xlim([-1, x_all.shape[1]])
plt.show()

